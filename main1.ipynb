{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "欢迎来到 YOLO 复现体验项目！！！让我们一起参考[《论文复现指南-cv版》](https://github.com/PaddlePaddle/models/blob/tipc/docs/lwfx/ArticleReproduction_CV.md)，按照步骤一步步完成[第四期飞桨论文复现赛](https://aistudio.baidu.com/aistudio/competition/detail/106/0/task-definition)真题：[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)，完整体验一篇经典论文的复现工作吧~\n",
    "\n",
    "本项目中，为了体验完整的论文复现流程，在每个重要的打卡点均设置了一些代码缺失，你需要参考[官方实现](https://github.com/yjh0410/new-YOLOv1_PyTorch)补齐代码，并运行结果对比工具 `reprod_log`，验证各打卡点是否通过。每个打卡点通过计 20 分，满分 100 分。准备好了吗？让我们一起开启有趣的 coding 练习吧~\n",
    "\n",
    "（注：如果你想复现其他方向的论文，欢迎参考[《论文复现指南-nlp版》](https://github.com/PaddlePaddle/models/blob/release/2.2/docs/lwfx/ArticleReproduction_NLP.md)、[《论文复现指南-Rec版》](https://github.com/PaddlePaddle/models/blob/release/2.2/docs/lwfx/ArticleReproduction_REC.md)）\n",
    "\n",
    "## 配置环境\n",
    "首先你需要安装论文复现赛中辅助自查和核验的工具 [reprod_log](https://github.com/WenmuZhou/reprod_log)，主要功能如下：\n",
    "- 存取指定节点的输入输出 `tensor`\n",
    "- 基于文件的 `tensor` 读写\n",
    "- 2个字典的对比验证\n",
    "- 对比结果的输出与记录\n",
    "\n",
    "（注：本项目中使用的 `reprod_log` 工具已随项目打包并适配了 aistudio，请参考以下操作安装，无需从 github 下载）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/reprod_log\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "installing to build/bdist.linux-x86_64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/wheel\n",
      "creating build/bdist.linux-x86_64/wheel/reprod_log\n",
      "copying build/lib/reprod_log/utils.py -> build/bdist.linux-x86_64/wheel/reprod_log\n",
      "copying build/lib/reprod_log/__init__.py -> build/bdist.linux-x86_64/wheel/reprod_log\n",
      "copying build/lib/reprod_log/compare.py -> build/bdist.linux-x86_64/wheel/reprod_log\n",
      "copying build/lib/reprod_log/ReprodDiffHelper.py -> build/bdist.linux-x86_64/wheel/reprod_log\n",
      "copying build/lib/reprod_log/ReprodLogger.py -> build/bdist.linux-x86_64/wheel/reprod_log\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "writing reprod_log.egg-info/PKG-INFO\n",
      "writing dependency_links to reprod_log.egg-info/dependency_links.txt\n",
      "writing top-level names to reprod_log.egg-info/top_level.txt\n",
      "reading manifest file 'reprod_log.egg-info/SOURCES.txt'\n",
      "writing manifest file 'reprod_log.egg-info/SOURCES.txt'\n",
      "Copying reprod_log.egg-info to build/bdist.linux-x86_64/wheel/reprod_log-1.0.0-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.linux-x86_64/wheel/reprod_log-1.0.0.dist-info/WHEEL\n",
      "creating 'dist/reprod_log-1.0.0-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "adding 'reprod_log/ReprodDiffHelper.py'\n",
      "adding 'reprod_log/ReprodLogger.py'\n",
      "adding 'reprod_log/__init__.py'\n",
      "adding 'reprod_log/compare.py'\n",
      "adding 'reprod_log/utils.py'\n",
      "adding 'reprod_log-1.0.0.dist-info/METADATA'\n",
      "adding 'reprod_log-1.0.0.dist-info/WHEEL'\n",
      "adding 'reprod_log-1.0.0.dist-info/top_level.txt'\n",
      "adding 'reprod_log-1.0.0.dist-info/RECORD'\n",
      "removing build/bdist.linux-x86_64/wheel\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Processing ./dist/reprod_log-1.0.0-py3-none-any.whl\n",
      "Installing collected packages: reprod-log\n",
      "Successfully installed reprod-log-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# 安装对比工具reprod_log\n",
    "%cd /home/aistudio/reprod_log\n",
    "!python setup.py bdist_wheel\n",
    "!pip install dist/reprod_log-1.0.0-py3-none-any.whl --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 论文介绍\n",
    "\n",
    "复现代码之前，先来认识一下我们要复现的经典检测模型 YOLO，这是一个端到端的目标检测算法，与之前的多阶段目标检测算法不同，YOLO 只需要进行一次 CNN 网络计算即可得到预测结果，这使得 YOLO 模型成为了业界公认的高精度、高效率、高实用性的模型。\n",
    "\n",
    "<div align='left'>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/a0b2ba74d09b46659ee2ee2107d06be9b190f87eeb96459ca8c64bd93c4fd468' width='600'/>\n",
    "</div>\n",
    "\n",
    "目前 YOLO 模型已经得到了学术界产业界的一致认可，并衍生出一系列的优质模型，其中包括 PaddleDetection 的明星模型 [PP-YOLO 和 PP-YOLOv2](https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.3/configs/ppyolo/README.md)，在速度和精度上甚至超过了官方团队新出的 YOLOv5。\n",
    "\n",
    "<div align='left'>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/72b419d96b4a441283693354075e7a6d51d124dffd134e42bb7d4a74dc074088' width='300'/>\n",
    "   <img src='https://ai-studio-static-online.cdn.bcebos.com/eb5d319ec175401783a92a8dd2b5ab27f525d8e962514a8e90c34fe1c6948a16' width='300'/>\n",
    "</div>\n",
    "\n",
    "YOLO 是如何实现\"只用看一次\"就得到目标检测框和物体分类结果的呢？整体来看，YOLO 算法采用一个单独的 CNN 模型实现端到端的目标检测，整个系统如下图所示：\n",
    "- 首先将输入图片 resize 到 448 x 448，送入 CNN 网络；\n",
    "- 之后网络将输入的图片分割成 S × S 网格，分别送到两条分支；\n",
    "- 上面的检测分支每个单元格负责去检测那些中心点落在该格子内的目标，例如图中狗的中心点落在第5行第2格，则这一格负责预测狗的检测框；下面的分类分支每个单元格需要预测格子中图像的分类，并给出置信度。\n",
    "- 最后结合检测分支与分类分支的输出结果，计算得出最终的检测图。\n",
    "\n",
    "<div align='left'>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/450744c2723e443c9fb6f4e5cd26980965beda300a5442a5bdb130fa9dad1d63' width='600'/>\n",
    "</div>\n",
    "\n",
    "\n",
    "## 开始练习\n",
    "面对一篇计算机视觉论文，复现该论文的整体流程如下图所示，总共包含11个步骤。为了高效复现论文，设置了5个打卡点，如图中黄色框所示。\n",
    "\n",
    "<div align='left'>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/6198b7f186454bdd82a39bb900ee544950e32ca7c13c4beba275a7f39048adea' width='800'/>\n",
    "</div>\n",
    "\n",
    "接下来，我们将参考上图复现流程，逐步对齐并通过打卡点，复现 YOLO 模型。\n",
    "\n",
    "### 打卡点1：前向对齐（含Step1：模型结构对齐）\n",
    "对齐模型结构时，一般有3个主要步骤：\n",
    "- 网络结构代码转换\n",
    "- 权重转换\n",
    "- 模型组网正确性验证\n",
    "\n",
    "在本项目中，已完成了权重转换与组网正确性验证部分的代码，你只需要在网络结构代码 `.YOLO_reprod/checkpoint_1/yolo_paddle/models/yolo.py` 中，补齐 `forward` 部分的代码缺失，并运行以下指令测试参考模型与自己的模型的一次前向计算输出误差，并打印 log，测试打卡点1是否对齐。\n",
    "```\n",
    "cd ~/YOLO_reprod/checkpoint_1/yolo_paddle/\n",
    "python forward_yolo.py\n",
    "\n",
    "cd..\n",
    "python checkpoint_1.py\n",
    "```\n",
    "\n",
    "注：\n",
    "- 参考模型的网络结构代码放在 `~/YOLO_reprod/checkpoint_1/yolo_torch/models/yolo.py`，你可以参考这部分代码转写你的 paddle 模型代码；\n",
    "- 权重转换代码放在 `~/YOLO_reprod/weights_trans/torch2paddle.py`，有兴趣可以自行研读，模型转换的注意事项详见[《论文复现手册》](https://github.com/PaddlePaddle/models/blob/release/2.2/docs/lwfx/ArticleReproduction_CV.md#312-%E6%9D%83%E9%87%8D%E8%BD%AC%E6%8D%A2)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载官方实现模型权重，转换为paddle模型权重(此步骤跳过，转换后模型已存储在 ~/YOLO_reprod/weights_trans/yolo_paddle.pdparams)\n",
    "# %cd /home/aistudio/YOLO_reprod/weights_trans/\n",
    "# !python torch2paddle.py\n",
    "\n",
    "# 生成假数据(此步骤跳过，假数据与假标签已存储在 ~/YOLO_reprod/fake_data/)\n",
    "# %cd /home/aistudio/YOLO_reprod/fake_data/\n",
    "# !python gen_fake_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_1/yolo_paddle\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/home/aistudio/YOLO_reprod/checkpoint_1\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "[2022/01/10 10:26:10] root INFO: logits: \n",
      "[2022/01/10 10:26:10] root INFO: \tmean diff: check passed: True, value: 1.155436994173588e-07\n",
      "[2022/01/10 10:26:10] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "# 打卡点1对齐（对齐网络结构）\n",
    "# 生成paddle的前向数据\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_1/yolo_paddle/\n",
    "!python forward_yolo.py\n",
    "\n",
    "# 与官方实现模型的前向数据对比，生成log\n",
    "%cd ..\n",
    "!python checkpoint_1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "恭喜你对齐了打卡点1：前向对齐！！！接下来要完成打卡点2：评估对齐，这一步包含两个步骤，你需要读取测试数据后，使用转换后模型进行评估，并实现评估指标对齐。\n",
    "\n",
    "### 打卡点2：评估对齐（含Step 2：验证/测试集数据读取对齐、Step 3：评估指标对齐）\n",
    "对齐评估指标，你需要完成Step 2：验证/测试集数据读取对齐 和 Step 3：评估指标对齐，分别会打印两个对齐 log。\n",
    "\n",
    "首先是 **Step 2：验证/测试集数据读取对齐**，在这一步，我们需要\n",
    "* 将 aistudio 挂载的数据集 VOCdevkit 解压；\n",
    "* 参考官方实现代码转写 paddle 数据加载代码；\n",
    "* 固定预处理方式，在 `~/YOLO_reprod/checkpoint_2/test_vocdata.py` 中定义 `dataset` 与 `dataloader` ，对比输出误差，打印 log。\n",
    "\n",
    "注：由于 `dataset` 与 `dataloader` 输出对齐中涉及的数据量较大，无法打包保存在项目中，**此步骤跳过**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_2\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/setuptools/depends.py:2: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "Traceback (most recent call last):\n",
      "  File \"test_vocdata.py\", line 86, in <module>\n",
      "    test_data_pipeline()\n",
      "  File \"test_vocdata.py\", line 58, in test_data_pipeline\n",
      "    paddle_dataset, paddle_dataloader = build_paddle_data_pipeline()\n",
      "  File \"test_vocdata.py\", line 42, in build_paddle_data_pipeline\n",
      "    transform=BaseTransform((train_size), (0, 0, 0))\n",
      "  File \"/home/aistudio/YOLO_reprod/checkpoint_2/yolo_paddle/data/voc0712.py\", line 117, in __init__\n",
      "    for line in open(osp.join(rootpath, 'ImageSets', 'Main', name + '.txt')):\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/bml/.storage/mnt/v-uimvattx3skxxwr7/org/workflow/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt'\n"
     ]
    }
   ],
   "source": [
    "# dataset与dataloader输出对齐(涉及数据量较大，不便于在aistudio操作，此步跳过)\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_2/\n",
    "!python test_vocdata.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "接下来是 **Step 3：评估指标对齐**，在这一步，我们需要：\n",
    "* 将测试集数据载入网络，定义模型的 `eval` 部分代码；\n",
    "* 打印评估结果并将评估指标 `mAP` 保存；\n",
    "* 评估指标正确性验证。\n",
    "\n",
    "在本项目中，你需要在 `~/YOLO_reprod/checkpoint_2/yolo_paddle/metric_eval.py` 中完成 `voc_test` 部分的代码缺失，并运行以下指令测试参考代码与自己的 `eval` 代码的评估指标输出误差，并打印 log，测试打卡点2是否对齐。\n",
    "```\n",
    "cd ~/YOLO_reprod/checkpoint_2/yolo_paddle/\n",
    "sh run_eval.sh\n",
    "\n",
    "cd ..\n",
    "python checkpoint_2.py\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "# 解压数据集\n",
    "%cd /home/aistudio/\n",
    "!tar -xf /home/aistudio/data/data9837/VOCtrainval_06-Nov-2007.tar\n",
    "!tar -xf /home/aistudio/data/data9837/VOCtest_06-Nov-2007.tar\n",
    "!tar -xf /home/aistudio/data/data9837/VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_2/yolo_paddle\n",
      "eval on voc ...\n",
      "use gpu\n",
      "W0110 10:39:58.974001   376 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0110 10:39:58.977844   376 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "# 打卡点2对齐（对齐评估指标）\n",
    "# 评估paddle模型，生成评估指标map\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_2/yolo_paddle/\n",
    "!sh run_eval.sh\n",
    "    \n",
    "# 与官方实现模型的评估指标数据对比，生成log\n",
    "%cd ..\n",
    "!python checkpoint_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "恭喜你对齐了打卡点2：评估对齐！！！接下来要完成打卡点3：损失函数对齐。\n",
    "\n",
    "### 打卡点3：损失函数对齐（含 Step 4:损失函数对齐）\n",
    "对齐损失函数，你需要参考以下步骤：\n",
    "* 定义模型训练代码，加载权重与假数据假标签，获取一次前向计算的 loss 结果并保存；\n",
    "* 损失函数正确性验证。\n",
    "\n",
    "在本项目中，你需要在 `~/YOLO_reprod/checkpoint_3/yolo_paddle/tools.py` 中完成 `loss` 部分的代码缺失，并运行以下指令测试参考代码与自己代码的一次前向训练输出误差，并打印 log，测试打卡点3是否对齐。\n",
    "```\n",
    "cd ~/YOLO_reprod/checkpoint_3/yolo_paddle/\n",
    "python loss_train.py\n",
    "\n",
    "cd ..\n",
    "python checkpoint_3.py\n",
    "```\n",
    "注：\n",
    "`CrossEntropyLoss`有一定的区别需要注意：PaddlePaddle 提供了对软标签、指定 softmax 计算纬度的支持。即 `paddle.nn.CrossEntropyLoss` 默认是在最后一维(axis=-1)计算损失函数，而 `torch.nn.CrossEntropyLoss` 是在axis=1的地方计算损失函数，因此如果输入的维度大于 2，这里需要保证计算的维(axis)相同，否则可能会出错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_3/yolo_paddle\n",
      "/home/aistudio/YOLO_reprod/checkpoint_3\n",
      "[2022/01/10 11:20:26] root INFO: conf_loss: \n",
      "[2022/01/10 11:20:26] root INFO: \tmean diff: check passed: True, value: 5.982089037459559e-07\n",
      "[2022/01/10 11:20:26] root INFO: cls_loss: \n",
      "[2022/01/10 11:20:26] root INFO: \tmean diff: check passed: True, value: 7.152557373046875e-07\n",
      "[2022/01/10 11:20:26] root INFO: txtytwth_loss: \n",
      "[2022/01/10 11:20:26] root INFO: \tmean diff: check passed: True, value: 4.291534423828125e-06\n",
      "[2022/01/10 11:20:26] root INFO: total_loss: \n",
      "[2022/01/10 11:20:26] root INFO: \tmean diff: check passed: True, value: 3.2164883627672225e-06\n",
      "[2022/01/10 11:20:26] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "# 打卡点3对齐（对齐损失函数）\n",
    "# 使用假数据与假标签获取paddle模型的损失函数\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_3/yolo_paddle/\n",
    "!python loss_train.py\n",
    "\n",
    "# 与官方实现模型的损失函数数据对比，生成log，阈值改为1e-5\n",
    "%cd ..\n",
    "!python checkpoint_3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "恭喜你对齐了打卡点3：损失函数对齐！！！接下来要完成打卡点4：反向对齐。本步骤包含：优化器对齐、学习率对齐、正则化策略对齐和反向对齐。其中，正则化策略在 YOLO 中是写死的，因此该步骤跳过。我们可以划分为两大步骤完成：优化器学习率对齐和反向对齐。\n",
    "\n",
    "### 打卡点4：反向对齐（含 Step 5：优化器对齐、Step 6：学习率对齐、Step 7：正则化策略对齐、Step 8：反向对齐）\n",
    "\n",
    "对齐反向计算，你需要完成Step 5+6：优化器学习率对齐 和 Step 8：反向对齐，分别会打印两个对齐 log。每个 log 计 10 分。\n",
    "\n",
    "首先是 **Step 5+6：优化器学习率对齐**，在这一步，我们需要\n",
    "* 定义优化器\n",
    "* 定义学习率规则\n",
    "* 设置 90 个 epoch，将每个 epoch 的学习率保存\n",
    "* 比对学习率正确性\n",
    "\n",
    "在本项目中，你需要在 `~/YOLO_reprod/checkpoint_4/yolo_paddle/lr_optim_eval.py` 中完成 **优化器与学习率** 部分的代码缺失，并运行以下指令测试参考代码与自己代码的若干次学习率输出误差，并打印 log。\n",
    "```\n",
    "cd ~/YOLO_reprod/checkpoint_4/yolo_paddle/\n",
    "python lr_optim_eval.py\n",
    "\n",
    "cd ..\n",
    "python test_lr.py\n",
    "```\n",
    "注：\n",
    "- PaddlePaddle 的 `SGD` 不支持动量更新、动量衰减和 `Nesterov` 动量，这里需要使用 1paddle.optimizer.Momentum` API实现这些功能。\n",
    "- PaddlePaddle 定义的优化器支持 `optimizer.set_lr()` 方式直接修改学习率，而不需要额外定义 `set_lr` 的函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_4/yolo_paddle\n",
      "/home/aistudio/YOLO_reprod/checkpoint_4\n",
      "[2022/01/10 12:37:02] root INFO: lr: \n",
      "[2022/01/10 12:37:02] root INFO: \tmean diff: check passed: True, value: 0.0\n",
      "[2022/01/10 12:37:02] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "# 优化器与学习率对齐\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_4/yolo_paddle/\n",
    "!python lr_optim_eval.py\n",
    "\n",
    "%cd ..\n",
    "!python test_lr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "接下来是 **Step 8：反向对齐**，此处推荐使用假数据与假标签，实现可复现的结果。在这一步，我们需要\n",
    "* 检查两个代码的训练超参数全部一致，如优化器及其超参数、学习率、BatchNorm/LayerNorm中的eps等；\n",
    "* 将 PaddlePaddle 与 PyTorch 网络中涉及的所有随机操作全部关闭，如 `dropout`、`drop_path` 等，推荐将模型设置为 `eval` 模式（ `model.eval()` ）；\n",
    "* 加载相同的模型权重，将准备好的数据分别传入网络并迭代，观察二者loss是否一致（此处 `batch_size` 要一致，如果使用多个真实数据，要保证传入网络的顺序一致）；\n",
    "* 如果经过2轮以上，loss 均可以对齐，则基本可以认为反向对齐。\n",
    "\n",
    "在本项目中，你需要把上一步中定义的优化器放置在反向对齐代码 `~/YOLO_reprod/checkpoint_4/yolo_paddle/bp_train.py` 中，并运行以下指令测试参考代码与自己代码的 2 次以上损失函数输出误差，并打印 log，测试打卡点4是否对齐。\n",
    "```\n",
    "cd ~/YOLO_reprod/checkpoint_4/yolo_paddle/\n",
    "python bp_train.py\n",
    "\n",
    "cd ..\n",
    "python checkpoint_4.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_4/yolo_paddle\n",
      "W0110 16:45:33.614033  1644 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0110 16:45:33.618849  1644 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "/home/aistudio/YOLO_reprod/checkpoint_4\n",
      "[2022/01/10 16:45:40] root INFO: conf_loss_0: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 6.395274043669019e-08\n",
      "[2022/01/10 16:45:40] root INFO: conf_loss_1: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 2.4378674656766464e-06\n",
      "[2022/01/10 16:45:40] root INFO: conf_loss_2: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 9.078661482142536e-06\n",
      "[2022/01/10 16:45:40] root INFO: conf_loss_3: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 2.107878318646783e-05\n",
      "[2022/01/10 16:45:40] root INFO: conf_loss_4: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 1.6764994430928937e-05\n",
      "[2022/01/10 16:45:40] root INFO: cls_loss_0: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 0.0\n",
      "[2022/01/10 16:45:40] root INFO: cls_loss_1: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 1.9073486328125e-06\n",
      "[2022/01/10 16:45:40] root INFO: cls_loss_2: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 7.152557373046875e-07\n",
      "[2022/01/10 16:45:40] root INFO: cls_loss_3: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 4.756450653076172e-05\n",
      "[2022/01/10 16:45:40] root INFO: cls_loss_4: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 5.269050598144531e-05\n",
      "[2022/01/10 16:45:40] root INFO: txtytwth_loss_0: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 0.0\n",
      "[2022/01/10 16:45:40] root INFO: txtytwth_loss_1: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 1.6689300537109375e-06\n",
      "[2022/01/10 16:45:40] root INFO: txtytwth_loss_2: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 2.384185791015625e-06\n",
      "[2022/01/10 16:45:40] root INFO: txtytwth_loss_3: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 2.6226043701171875e-06\n",
      "[2022/01/10 16:45:40] root INFO: txtytwth_loss_4: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 2.9325485229492188e-05\n",
      "[2022/01/10 16:45:40] root INFO: total_loss_0: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 6.395273999260098e-08\n",
      "[2022/01/10 16:45:40] root INFO: total_loss_1: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 1.961030307029432e-06\n",
      "[2022/01/10 16:45:40] root INFO: total_loss_2: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: True, value: 7.40973142754342e-06\n",
      "[2022/01/10 16:45:40] root INFO: total_loss_3: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 6.590147605756158e-05\n",
      "[2022/01/10 16:45:40] root INFO: total_loss_4: \n",
      "[2022/01/10 16:45:40] root INFO: \tmean diff: check passed: False, value: 9.878098564186644e-05\n",
      "[2022/01/10 16:45:40] root INFO: diff check failed\n"
     ]
    }
   ],
   "source": [
    "# 打卡点4对齐（对齐反向传播）\n",
    "# 使用假数据与假标签获取paddle模型的5个epoch反向损失函数\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_4/yolo_paddle/\n",
    "!python bp_train.py\n",
    "\n",
    "# 与官方实现模型的反向传播数据对比，生成log，阈值改为1e-5\n",
    "%cd ..\n",
    "!python checkpoint_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "恭喜你对齐了打卡点4：反向对齐！！！接下来要完成打卡点5：精度对齐。训练集和测试集数据读取方式相似，因此 Step9 可以跳过；conv+bn 结构的 CNN 网络通常对网络初始化并不敏感，因此选择随机初始化即可， Step10 也可以跳过；本节我们重点调整 Step11：训练对齐。\n",
    "\n",
    "### 打卡点5：精度对齐（含 Step9：训练集数据读取对齐、Step10：网络初始化对齐、Step11：训练对齐）\n",
    "\n",
    "终于到了最激动人心的训练环节，~~让我们一把梭哈，不行回家~~~经过前4步的对齐，通常来讲训练精度不会有特别大的误差，我们定义好训练代码 `train.py` 后，就可以开启漫长的深度学习训练过程了。\n",
    "\n",
    "注：由于 YOLO 训练时间过久，有兴趣的同学可以尝试训练一下，若你时间有限，也可以加载 `YOLO_reprod/checkpoint_5/yolo_paddle/yolo-model.pdparams` 权重参数，进行后续的打卡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle\n",
      "W0110 16:48:49.422663  2017 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0110 16:48:49.427881  2017 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "im_detect: 1/4952 0.025s\n",
      "im_detect: 501/4952 0.020s\n",
      "im_detect: 1001/4952 0.021s\n",
      "im_detect: 1501/4952 0.020s\n",
      "im_detect: 2001/4952 0.021s\n",
      "im_detect: 2501/4952 0.021s\n",
      "im_detect: 3001/4952 0.019s\n",
      "im_detect: 3501/4952 0.019s\n",
      "im_detect: 4001/4952 0.029s\n",
      "im_detect: 4501/4952 0.022s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.0000\n",
      "AP for bicycle = 0.0007\n",
      "AP for bird = 0.0003\n",
      "AP for boat = 0.0000\n",
      "AP for bottle = 0.0001\n",
      "AP for bus = 0.0000\n",
      "AP for car = 0.0057\n",
      "AP for cat = 0.0041\n",
      "AP for chair = 0.0006\n",
      "AP for cow = 0.0000\n",
      "AP for diningtable = 0.0000\n",
      "AP for dog = 0.0015\n",
      "AP for horse = 0.0002\n",
      "AP for motorbike = 0.0002\n",
      "AP for person = 0.0078\n",
      "AP for pottedplant = 0.0000\n",
      "AP for sheep = 0.0000\n",
      "AP for sofa = 0.0000\n",
      "AP for train = 0.0000\n",
      "AP for tvmonitor = 0.0001\n",
      "Mean AP = 0.0011\n",
      "Mean AP:  0.0010658159620122874\n",
      "im_detect: 1/4952 0.023s\n",
      "im_detect: 501/4952 0.022s\n",
      "im_detect: 1001/4952 0.018s\n",
      "im_detect: 1501/4952 0.018s\n",
      "im_detect: 2001/4952 0.020s\n",
      "im_detect: 2501/4952 0.020s\n",
      "im_detect: 3001/4952 0.020s\n",
      "im_detect: 3501/4952 0.019s\n",
      "im_detect: 4001/4952 0.019s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.0212\n",
      "AP for bicycle = 0.0152\n",
      "AP for bird = 0.0074\n",
      "AP for boat = 0.0000\n",
      "AP for bottle = 0.0000\n",
      "AP for bus = 0.0043\n",
      "AP for car = 0.1111\n",
      "AP for cat = 0.0922\n",
      "AP for chair = 0.0946\n",
      "AP for cow = 0.0040\n",
      "AP for diningtable = 0.0000\n",
      "AP for dog = 0.0455\n",
      "AP for horse = 0.0000\n",
      "AP for motorbike = -1.0000\n",
      "AP for person = 0.0678\n",
      "AP for pottedplant = 0.0070\n",
      "AP for sheep = 0.0091\n",
      "AP for sofa = 0.0000\n",
      "AP for train = 0.0227\n",
      "AP for tvmonitor = 0.0000\n",
      "Mean AP = -0.0249\n",
      "Mean AP:  -0.02490171029988064\n",
      "im_detect: 1/4952 0.022s\n",
      "im_detect: 501/4952 0.019s\n",
      "im_detect: 1001/4952 0.020s\n",
      "im_detect: 1501/4952 0.029s\n",
      "im_detect: 2001/4952 0.021s\n",
      "im_detect: 2501/4952 0.023s\n",
      "im_detect: 3001/4952 0.020s\n",
      "im_detect: 3501/4952 0.022s\n",
      "im_detect: 4001/4952 0.019s\n",
      "im_detect: 4501/4952 0.022s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.1509\n",
      "AP for bicycle = 0.3526\n",
      "AP for bird = 0.1625\n",
      "AP for boat = 0.0172\n",
      "AP for bottle = 0.0186\n",
      "AP for bus = 0.1366\n",
      "AP for car = 0.2155\n",
      "AP for cat = 0.5079\n",
      "AP for chair = 0.1641\n",
      "AP for cow = 0.0909\n",
      "AP for diningtable = 0.1068\n",
      "AP for dog = 0.3881\n",
      "AP for horse = 0.2189\n",
      "AP for motorbike = 0.1963\n",
      "AP for person = 0.3866\n",
      "AP for pottedplant = 0.0166\n",
      "AP for sheep = 0.1229\n",
      "AP for sofa = 0.1253\n",
      "AP for train = 0.2776\n",
      "AP for tvmonitor = 0.1534\n",
      "Mean AP = 0.1905\n",
      "Mean AP:  0.19047262280678173\n",
      "im_detect: 1/4952 0.023s\n",
      "im_detect: 501/4952 0.021s\n",
      "im_detect: 1001/4952 0.018s\n",
      "im_detect: 1501/4952 0.018s\n",
      "im_detect: 2001/4952 0.019s\n",
      "im_detect: 2501/4952 0.019s\n",
      "im_detect: 3001/4952 0.020s\n",
      "im_detect: 3501/4952 0.018s\n",
      "im_detect: 4001/4952 0.020s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.4324\n",
      "AP for bicycle = 0.3586\n",
      "AP for bird = 0.2611\n",
      "AP for boat = 0.1608\n",
      "AP for bottle = 0.0712\n",
      "AP for bus = 0.3236\n",
      "AP for car = 0.4354\n",
      "AP for cat = 0.5678\n",
      "AP for chair = 0.1545\n",
      "AP for cow = 0.0512\n",
      "AP for diningtable = 0.1276\n",
      "AP for dog = 0.2366\n",
      "AP for horse = 0.1647\n",
      "AP for motorbike = 0.3465\n",
      "AP for person = 0.1413\n",
      "AP for pottedplant = 0.1102\n",
      "AP for sheep = 0.2246\n",
      "AP for sofa = 0.2324\n",
      "AP for train = 0.5091\n",
      "AP for tvmonitor = 0.2311\n",
      "Mean AP = 0.2570\n",
      "Mean AP:  0.2570394608268857\n",
      "im_detect: 1/4952 0.024s\n",
      "im_detect: 501/4952 0.022s\n",
      "im_detect: 1001/4952 0.019s\n",
      "im_detect: 1501/4952 0.019s\n",
      "im_detect: 2001/4952 0.021s\n",
      "im_detect: 2501/4952 0.022s\n",
      "im_detect: 3001/4952 0.020s\n",
      "im_detect: 3501/4952 0.019s\n",
      "im_detect: 4001/4952 0.018s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.3564\n",
      "AP for bicycle = 0.5243\n",
      "AP for bird = 0.2608\n",
      "AP for boat = 0.1642\n",
      "AP for bottle = 0.1707\n",
      "AP for bus = 0.4287\n",
      "AP for car = 0.4856\n",
      "AP for cat = 0.6809\n",
      "AP for chair = 0.2205\n",
      "AP for cow = 0.3324\n",
      "AP for diningtable = 0.2322\n",
      "AP for dog = 0.5622\n",
      "AP for horse = 0.5180\n",
      "AP for motorbike = 0.5624\n",
      "AP for person = 0.4203\n",
      "AP for pottedplant = 0.1472\n",
      "AP for sheep = 0.3069\n",
      "AP for sofa = 0.4152\n",
      "AP for train = 0.4722\n",
      "AP for tvmonitor = 0.3625\n",
      "Mean AP = 0.3812\n",
      "Mean AP:  0.3811710405311147\n",
      "im_detect: 1/4952 0.023s\n",
      "im_detect: 501/4952 0.018s\n",
      "im_detect: 1001/4952 0.019s\n",
      "im_detect: 1501/4952 0.020s\n",
      "im_detect: 2001/4952 0.019s\n",
      "im_detect: 2501/4952 0.019s\n",
      "im_detect: 3001/4952 0.020s\n",
      "im_detect: 3501/4952 0.018s\n",
      "im_detect: 4001/4952 0.022s\n",
      "im_detect: 4501/4952 0.021s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.4547\n",
      "AP for bicycle = 0.5265\n",
      "AP for bird = 0.3436\n",
      "AP for boat = 0.2410\n",
      "AP for bottle = 0.1778\n",
      "AP for bus = 0.4726\n",
      "AP for car = 0.6030\n",
      "AP for cat = 0.6840\n",
      "AP for chair = 0.1913\n",
      "AP for cow = 0.3837\n",
      "AP for diningtable = 0.2661\n",
      "AP for dog = 0.5731\n",
      "AP for horse = 0.5495\n",
      "AP for motorbike = 0.5884\n",
      "AP for person = 0.4414\n",
      "AP for pottedplant = 0.1327\n",
      "AP for sheep = 0.4547\n",
      "AP for sofa = 0.3362\n",
      "AP for train = 0.5564\n",
      "AP for tvmonitor = 0.4206\n",
      "Mean AP = 0.4199\n",
      "Mean AP:  0.4198646255043159\n",
      "im_detect: 1/4952 0.023s\n",
      "im_detect: 501/4952 0.020s\n",
      "im_detect: 1001/4952 0.020s\n",
      "im_detect: 1501/4952 0.020s\n",
      "im_detect: 2001/4952 0.020s\n",
      "im_detect: 2501/4952 0.021s\n",
      "im_detect: 3001/4952 0.021s\n",
      "im_detect: 3501/4952 0.018s\n",
      "im_detect: 4001/4952 0.019s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.4854\n",
      "AP for bicycle = 0.2227\n",
      "AP for bird = 0.3550\n",
      "AP for boat = 0.2218\n",
      "AP for bottle = 0.1257\n",
      "AP for bus = 0.2898\n",
      "AP for car = 0.5449\n",
      "AP for cat = 0.7021\n",
      "AP for chair = 0.2832\n",
      "AP for cow = 0.2316\n",
      "AP for diningtable = 0.1089\n",
      "AP for dog = 0.5643\n",
      "AP for horse = 0.5480\n",
      "AP for motorbike = 0.4940\n",
      "AP for person = 0.3540\n",
      "AP for pottedplant = 0.1141\n",
      "AP for sheep = 0.4358\n",
      "AP for sofa = 0.4103\n",
      "AP for train = 0.5749\n",
      "AP for tvmonitor = 0.4817\n",
      "Mean AP = 0.3774\n",
      "Mean AP:  0.37741692343365535\n",
      "im_detect: 1/4952 0.044s\n",
      "im_detect: 501/4952 0.023s\n",
      "im_detect: 1001/4952 0.019s\n",
      "im_detect: 1501/4952 0.019s\n",
      "im_detect: 2001/4952 0.021s\n",
      "im_detect: 2501/4952 0.021s\n",
      "im_detect: 3001/4952 0.019s\n",
      "im_detect: 3501/4952 0.020s\n",
      "im_detect: 4001/4952 0.019s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.4502\n",
      "AP for bicycle = 0.6480\n",
      "AP for bird = 0.5105\n",
      "AP for boat = 0.2824\n",
      "AP for bottle = 0.1906\n",
      "AP for bus = 0.5059\n",
      "AP for car = 0.5646\n",
      "AP for cat = 0.7510\n",
      "AP for chair = 0.2887\n",
      "AP for cow = 0.3259\n",
      "AP for diningtable = 0.3868\n",
      "AP for dog = 0.7292\n",
      "AP for horse = 0.6649\n",
      "AP for motorbike = 0.6181\n",
      "AP for person = 0.4025\n",
      "AP for pottedplant = 0.2197\n",
      "AP for sheep = 0.2373\n",
      "AP for sofa = 0.4211\n",
      "AP for train = 0.6363\n",
      "AP for tvmonitor = 0.5019\n",
      "Mean AP = 0.4668\n",
      "Mean AP:  0.4667866726400886\n",
      "im_detect: 1/4952 0.026s\n",
      "im_detect: 501/4952 0.020s\n",
      "im_detect: 1001/4952 0.018s\n",
      "im_detect: 1501/4952 0.018s\n",
      "im_detect: 2001/4952 0.019s\n",
      "im_detect: 2501/4952 0.022s\n",
      "im_detect: 3001/4952 0.021s\n",
      "im_detect: 3501/4952 0.021s\n",
      "im_detect: 4001/4952 0.022s\n",
      "im_detect: 4501/4952 0.024s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.5538\n",
      "AP for bicycle = 0.5455\n",
      "AP for bird = 0.3885\n",
      "AP for boat = 0.2816\n",
      "AP for bottle = 0.1996\n",
      "AP for bus = 0.4769\n",
      "AP for car = 0.5698\n",
      "AP for cat = 0.6469\n",
      "AP for chair = 0.1434\n",
      "AP for cow = 0.3878\n",
      "AP for diningtable = 0.1704\n",
      "AP for dog = 0.5923\n",
      "AP for horse = 0.5898\n",
      "AP for motorbike = 0.6200\n",
      "AP for person = 0.4434\n",
      "AP for pottedplant = 0.1486\n",
      "AP for sheep = 0.4295\n",
      "AP for sofa = 0.1151\n",
      "AP for train = 0.6063\n",
      "AP for tvmonitor = 0.1416\n",
      "Mean AP = 0.4026\n",
      "Mean AP:  0.40256051287265776\n",
      "im_detect: 1/4952 0.023s\n",
      "im_detect: 501/4952 0.019s\n",
      "im_detect: 1001/4952 0.019s\n",
      "im_detect: 1501/4952 0.018s\n",
      "im_detect: 2001/4952 0.020s\n",
      "im_detect: 2501/4952 0.020s\n",
      "im_detect: 3001/4952 0.019s\n",
      "im_detect: 3501/4952 0.018s\n",
      "im_detect: 4001/4952 0.019s\n",
      "im_detect: 4501/4952 0.019s\n",
      "Evaluating detections\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.6186\n",
      "AP for bicycle = 0.5079\n",
      "AP for bird = 0.5411\n",
      "AP for boat = 0.3790\n",
      "AP for bottle = 0.1776\n",
      "AP for bus = 0.5788\n",
      "AP for car = 0.6309\n",
      "AP for cat = 0.7360\n",
      "AP for chair = 0.3013\n",
      "AP for cow = 0.4682\n",
      "AP for diningtable = 0.4209\n",
      "AP for dog = 0.6547\n",
      "AP for horse = 0.5952\n",
      "AP for motorbike = 0.6494\n",
      "AP for person = 0.5489\n",
      "AP for pottedplant = 0.2659\n",
      "AP for sheep = 0.5346\n",
      "AP for sofa = 0.3822\n",
      "AP for train = 0.6860\n",
      "AP for tvmonitor = 0.5272\n",
      "Mean AP = 0.5102\n",
      "Mean AP:  0.5102289594032875\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 260, in <module>\n",
      "    train()\n",
      "  File \"train.py\", line 188, in train\n",
      "    for iter_i, (images, targets) in enumerate(dataloader):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 255, in __next__\n",
      "    data = self._reader.read_next_var_list()\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 213, in _thread_loop\n",
      "    self._thread_done_event)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/fetcher.py\", line 121, in fetch\n",
      "    data.append(self.dataset[idx])\n",
      "  File \"/home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle/data/voc0712.py\", line 113, in __getitem__\n",
      "    im, gt, h, w = self.pull_item(index)\n",
      "  File \"/home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle/data/voc0712.py\", line 145, in pull_item\n",
      "    return paddle.transpose(paddle.to_tensor(img),perm=[2,0,1]), target, height, width\n",
      "  File \"<decorator-gen-134>\", line 2, in to_tensor\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\", line 25, in __impl__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\", line 228, in __impl__\n",
      "    ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n",
      "AssertionError: We only support 'to_tensor()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 开始训练，并将最佳模型参数保存\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle\n",
    "!sh train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle\n",
      "eval on voc ...\n",
      "use gpu\n",
      "W0110 18:17:41.922364 10978 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0110 18:17:41.927183 10978 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "Finished loading model!\n",
      "im_detect: 1/4952 0.022s\n",
      "im_detect: 501/4952 0.016s\n",
      "im_detect: 1001/4952 0.015s\n",
      "im_detect: 1501/4952 0.015s\n",
      "im_detect: 2001/4952 0.018s\n",
      "im_detect: 2501/4952 0.017s\n",
      "im_detect: 3001/4952 0.016s\n",
      "im_detect: 3501/4952 0.016s\n",
      "im_detect: 4001/4952 0.016s\n",
      "im_detect: 4501/4952 0.017s\n",
      "Evaluating detections\n",
      "Writing aeroplane VOC results file\n",
      "Writing bicycle VOC results file\n",
      "Writing bird VOC results file\n",
      "Writing boat VOC results file\n",
      "Writing bottle VOC results file\n",
      "Writing bus VOC results file\n",
      "Writing car VOC results file\n",
      "Writing cat VOC results file\n",
      "Writing chair VOC results file\n",
      "Writing cow VOC results file\n",
      "Writing diningtable VOC results file\n",
      "Writing dog VOC results file\n",
      "Writing horse VOC results file\n",
      "Writing motorbike VOC results file\n",
      "Writing person VOC results file\n",
      "Writing pottedplant VOC results file\n",
      "Writing sheep VOC results file\n",
      "Writing sofa VOC results file\n",
      "Writing train VOC results file\n",
      "Writing tvmonitor VOC results file\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.6408\n",
      "AP for bicycle = 0.8016\n",
      "AP for bird = 0.6537\n",
      "AP for boat = 0.5582\n",
      "AP for bottle = 0.3597\n",
      "AP for bus = 0.7684\n",
      "AP for car = 0.7628\n",
      "AP for cat = 0.8651\n",
      "AP for chair = 0.4921\n",
      "AP for cow = 0.7290\n",
      "AP for diningtable = 0.6576\n",
      "AP for dog = 0.7613\n",
      "AP for horse = 0.7998\n",
      "AP for motorbike = 0.7801\n",
      "AP for person = 0.6783\n",
      "AP for pottedplant = 0.4181\n",
      "AP for sheep = 0.7439\n",
      "AP for sofa = 0.7287\n",
      "AP for train = 0.8175\n",
      "AP for tvmonitor = 0.6824\n",
      "Mean AP = 0.6850\n",
      "~~~~~~~~\n",
      "Results:\n",
      "0.641\n",
      "0.802\n",
      "0.654\n",
      "0.558\n",
      "0.360\n",
      "0.768\n",
      "0.763\n",
      "0.865\n",
      "0.492\n",
      "0.729\n",
      "0.658\n",
      "0.761\n",
      "0.800\n",
      "0.780\n",
      "0.678\n",
      "0.418\n",
      "0.744\n",
      "0.729\n",
      "0.817\n",
      "0.682\n",
      "0.685\n",
      "~~~~~~~~\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Results computed with the **unofficial** Python eval code.\n",
      "Results should be very close to the official MATLAB eval code.\n",
      "--------------------------------------------------------------\n",
      "Mean AP:  0.6849689955438324\n"
     ]
    }
   ],
   "source": [
    "# 测试训练最佳模型在测试集上的指标并保存\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_5/yolo_paddle/\n",
    "!sh eval.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/YOLO_reprod/checkpoint_5\n",
      "[2022/01/10 18:19:59] root INFO: map: \n",
      "[2022/01/10 18:19:59] root INFO: \tmean diff: check passed: True, value: 0.0002689957618713379\n",
      "[2022/01/10 18:19:59] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "# 对比精度，打印log，阈值调整为0.0015\n",
    "%cd /home/aistudio/YOLO_reprod/checkpoint_5/\n",
    "!python checkpoint_5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " **恭喜你完成了目标检测经典论文 YOLO 的代码复现！！！**  现在你已经是一个熟练的炼丹师了，快去开启你的深度学习之旅吧~你可以去 飞桨第五期论文复现挑战赛 选取自己感兴趣的论文并完成复现，会有丰厚奖金为你准备！你也可以选取一篇未列入复现赛的顶会论文自行复现，祝你好运哦~\n",
    "\n",
    "注：若是复现过程中遇到困难，你可以在 github 给我们提 issue，并在标题前备注【论文复现】，会有百度研发工程师为你解答~\n",
    "<div align='left'>\n",
    "  <img src='https://ai-studio-static-online.cdn.bcebos.com/f956037477fe42a0bdb172387c8cc37095805a2911c54125a6f93849523ab3fb' width='300'/>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
